{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our packages for numerical computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sla\n",
    "%matplotlib inline\n",
    "\n",
    "def mgs(A):\n",
    "    '''\n",
    "    Carry out modified Gram-Schmidt on A\n",
    "    Return reduced Q R\n",
    "    '''\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    \n",
    "    # Preallocate Q and R (more efficient)\n",
    "    Q = np.zeros( (m,n) )\n",
    "    R = np.zeros( (n,n) )\n",
    "    \n",
    "    # Skip pre-assignment loop of\n",
    "    #    v_i <-- a_i\n",
    "    # as done in Trefethen and Bau. We will just over-write A\n",
    "    # as we compute, i.e., v_i will always be the same thing as \n",
    "    # a_i. This saves space.\n",
    "    \n",
    "    # Loop over columns of A\n",
    "    for i in range(n):\n",
    "        # Form and store qj as column j in Q\n",
    "        R[i,i] = sla.norm(A[:,i])\n",
    "        Q[:,i] = A[:,i]/R[i,i]\n",
    "        \n",
    "        # Orthogonalize all columns j>i of V (really A) w.r.t. qi vj w.r.t. all the previous columns of A\n",
    "        #  Note: Python will not execute this loop for the i==j case \n",
    "        for j in range(i+1,n):\n",
    "            R[i,j] = np.dot(Q[:,i], A[:,j])\n",
    "            A[:,j] = A[:,j] - R[i,j]*Q[:,i]\n",
    "        \n",
    "    ## End loops    \n",
    "    return (Q,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = sp.rand(2,2)\n",
    "A3 = sp.rand(3,3)\n",
    "A4 = sp.rand(4,4)\n",
    "\n",
    "[Q2,R2] = mgs(A2)\n",
    "[Q3,R3] = mgs(A3)\n",
    "[Q4,R4] = mgs(A4)\n",
    "np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will check to see if the $ Q $ matricies from our $ Q R $ factorization are orthoganal. We want to see that $ Q Q^T = I $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -0.]\n",
      " [-0.  1.]]\n",
      "\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1. -0.]\n",
      " [ 0. -0.  1.]]\n",
      "\n",
      "[[ 1. -0.  0. -0.]\n",
      " [-0.  1. -0.  0.]\n",
      " [ 0. -0.  1. -0.]\n",
      " [-0.  0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(np.transpose(Q2),Q2))\n",
    "print()\n",
    "print(np.dot(np.transpose(Q3),Q3))\n",
    "print()\n",
    "print(np.dot(np.transpose(Q4),Q4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We now want to check if our $ R $ matricies are upper triangular. We can do this by simply looking at the shape of our 3 $ R $ matricies which we see are indeed upper triangular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98903 0.83226]\n",
      " [0.      0.43935]]\n",
      "\n",
      "[[0.61573 0.89112 0.47841]\n",
      " [0.      0.90249 0.41587]\n",
      " [0.      0.      0.31508]]\n",
      "\n",
      "[[1.02131 1.14885 0.71654 0.53643]\n",
      " [0.      1.03865 1.12221 0.65887]\n",
      " [0.      0.      0.5102  0.51634]\n",
      " [0.      0.      0.      0.51848]]\n"
     ]
    }
   ],
   "source": [
    "print(R2)\n",
    "print()\n",
    "print(R3)\n",
    "print()\n",
    "print(R4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we will check if $ A = Q R $ by computing $ A - Q R $ which effectivly shows the error in our $ Q R $ factorization. We ideally want $ A - Q R $ to equal the zero matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      -0.57325]\n",
      " [ 0.      -0.60336]]\n",
      "\n",
      "[[ 0.      -0.07027 -0.45058]\n",
      " [ 0.      -0.57424 -0.31604]\n",
      " [ 0.      -0.67779 -0.31451]]\n",
      "\n",
      "[[ 0.      -0.11705 -0.79584 -0.36859]\n",
      " [ 0.      -0.18173 -0.93218 -0.57124]\n",
      " [ 0.      -0.09785 -0.19604 -0.62822]\n",
      " [ 0.      -1.12408 -0.48169 -0.36283]]\n"
     ]
    }
   ],
   "source": [
    "print(A2-np.dot(Q2,R2))\n",
    "print()\n",
    "print(A3-np.dot(Q3,R3))\n",
    "print()\n",
    "print(A4-np.dot(Q4,R4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we would like to construct a matrix $ A $ such that the $ Q $ losses orthoginality in the $ Q R $ factorization of $ A $ using the mgs() routine. We know that if $ A $ has a very large condition number then there is going to be loss in orthoginality in the $ Q R $ factorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.783334468307216e+16\n"
     ]
    }
   ],
   "source": [
    "#Since we want A to have a large condtion number we can just pick a 2x2 matrix that has a large condition number and the Q \n",
    "#the QR factorization should lose orthoginality.\n",
    "\n",
    "A = np.array([[0.7, 0.7], [0.7, 0.7]])\n",
    "from numpy.linalg import cond \n",
    "#This will allow us to check the condition number of A\n",
    "print(cond(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the condition number of $ A $ is very large meaning that $ A $ is ill-conditioned. This is exactly what we want so that $ Q $ in the $ Q R $ factorization of $ A $ lost orthoginality. We will test the loss of orthoginality by using $$ \\| Q^* Q - I \\|_2 $$ (note: I Specifically made $ A $ singular.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730947\n"
     ]
    }
   ],
   "source": [
    "[Q,R]=mgs(A)\n",
    "print(sla.norm(np.dot(Q.T,Q) - np.eye(2)))\n",
    "# this shows us that Q lost orthoginality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we want to use SciPy's $ Q R $ to see if this method results in more or less lose in orthoginality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7194799110210365e-16\n"
     ]
    }
   ],
   "source": [
    "[sQ,sR]= sla.qr(A)\n",
    "print(sla.norm(np.dot(sQ.T,sQ) - np.eye(2)))\n",
    "# this shows us that Q maintained orthoginality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can clearly see that the SciPy method resulted in far less loss in orthoginality. We can see this because the value of $$ \\| Q^* Q - I \\|_2 $$ for the SciPy method was a lot smaller than for the mgs() method. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
