{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our packages for numerical computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sla\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compare Classical GS against Modified GS__\n",
    "- Review these implementations at home, comparing to the pseudocode in Trefethen and Bau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define function for classical Gram-Schmidt\n",
    "def classical_GS(A):\n",
    "    '''\n",
    "    Carry out classical Gram-Schmidt on A\n",
    "    Return reduced Q R\n",
    "    '''\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    \n",
    "    # Preallocate Q and R (more efficient)\n",
    "    Q = np.zeros( (m,n) )\n",
    "    R = np.zeros( (n,n) )\n",
    "    \n",
    "    # Loop over columns of A\n",
    "    for j in range(n):\n",
    "        # Create orthonormal qj based on column j of A\n",
    "        vj = A[:,j]\n",
    "        \n",
    "        # Orthogonalize vj w.r.t. all the previous columns of A\n",
    "        #  Note: Python will not execute this loop for the i==j case \n",
    "        for i in range(j):\n",
    "            R[i,j] = np.dot(Q[:,i], A[:,j])\n",
    "            vj = vj - R[i,j]*Q[:,i]\n",
    "        \n",
    "        # Set column j in Q\n",
    "        R[j,j] = sla.norm(vj)\n",
    "        Q[:,j] = vj/R[j,j]\n",
    "        \n",
    "    ## End loops    \n",
    "    return (Q,R)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, define function for Modified GS\n",
    "def mgs(A):\n",
    "    '''\n",
    "    Carry out modified Gram-Schmidt on A\n",
    "    Return reduced Q R\n",
    "    '''\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    \n",
    "    # Preallocate Q and R (more efficient)\n",
    "    Q = np.zeros( (m,n) )\n",
    "    R = np.zeros( (n,n) )\n",
    "    \n",
    "    # Skip pre-assignment loop of\n",
    "    #    v_i <-- a_i\n",
    "    # as done in Trefethen and Bau. We will just over-write A\n",
    "    # as we compute, i.e., v_i will always be the same thing as \n",
    "    # a_i. This saves space.\n",
    "    \n",
    "    # Loop over columns of A\n",
    "    for i in range(n):\n",
    "        # Form and store qj as column j in Q\n",
    "        R[i,i] = sla.norm(A[:,i])\n",
    "        Q[:,i] = A[:,i]/R[i,i]\n",
    "        \n",
    "        # Orthogonalize all columns j>i of V (really A) w.r.t. qi vj w.r.t. all the previous columns of A\n",
    "        #  Note: Python will not execute this loop for the i==j case \n",
    "        for j in range(i+1,n):\n",
    "            R[i,j] = np.dot(Q[:,i], A[:,j])\n",
    "            A[:,j] = A[:,j] - R[i,j]*Q[:,i]\n",
    "        \n",
    "    ## End loops    \n",
    "    return (Q,R)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod_GS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-668abfc89903>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mQ1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassical_GS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mQ2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod_GS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mQ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mod_GS' is not defined"
     ]
    }
   ],
   "source": [
    "# Sanity check that the implementation is OK\n",
    "A = sp.rand(5,5)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "[Q1,R1] = classical_GS(A)\n",
    "[Q2,R2] = mod_GS(A)\n",
    "print(Q1-Q2)\n",
    "print(\"----\")\n",
    "print(R1-R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's run an experiment__\n",
    "- Connect diagonal of $R$ to singular values\n",
    "- We first create a matrix $A$ with known singular values, using the the library $QR$ routine to generate the $U$ and $V$ for the manufactured SVD.  \n",
    "- That is, we manufacture the diagonal matrix $\\Sigma$, and form $A$ with\n",
    "$$ A = U \\Sigma V^* $$\n",
    "so that we know the singular values a priori.  \n",
    "- We generate the $U$ and $V^*$ by using $QR$ on random matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate this A with the below geometrically shrinking singular values\n",
    "n = 80\n",
    "[U,X] = sla.qr( sp.rand(n,n))\n",
    "[Vt,X] = sla.qr( sp.rand(n,n))\n",
    "S = sp.diag( 2.0**sp.arange(-1,-81,-1) )\n",
    "A = np.dot(U, np.dot(S, Vt))\n",
    "print(sp.diag(S[0:8]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we generate two separate $QR$ factorizations using both classical and modified G-S\n",
    "- We plot the diagonal elements of both $R$, followed by a discussion of this experiment below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Q1,R1] = classical_GS(A.copy())\n",
    "[Q2,R2] = mod_GS(A.copy())\n",
    "# Plot diagonal elements of R1 and R2\n",
    "plt.semilogy(sp.diag(R1), 'sk', linewidth=2)\n",
    "plt.semilogy(sp.diag(R2), 'or', linewidth=2)\n",
    "\n",
    "# Plot 2^{-j} as reference, these are the singular values\n",
    "plt.semilogy(sp.diag(S), '-b', linewidth=2)\n",
    "\n",
    "# Plot reference lines for machine epsilon, and sqrt(eps)\n",
    "eps = np.finfo(float).eps\n",
    "plt.semilogy([0,80], [eps,eps], 'g')\n",
    "plt.semilogy([0,80], [np.sqrt(eps),np.sqrt(eps)], 'm')\n",
    "\n",
    "plt.legend(['Classical', 'Modified', '$\\sigma_j=2^{-j}$', '$\\epsilon_{mach}$', '$\\sqrt{\\epsilon_{mach}}$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So, what exactly is going on here?__\n",
    "- $r_{jj} = \\|P_j a_j\\|$, so this gives us an indication of how large each projection is\n",
    "\n",
    "- We see that the $r_{jj}$ decrease steadily, tracking (roughly) the plot of the manufactured singular values $\\sigma_j$\n",
    "\n",
    "- But, $r_{jj} \\neq \\sigma_j$.  These values are just roughly similar.\n",
    "\n",
    "- Why is this? Well..\n",
    "    - We can rewrite $A = U \\Sigma V^T$, as \n",
    "    $$ A = 2^{-1} u_1 v^T_1 + 2^{-2} u_2 v^T_2 + \\dots + 2^{-80} u_{80} v^T_{80} $$ \n",
    "    \n",
    "    - Rearranging this, we can write the $j$th column of $A$ as \n",
    "    $$a_j = \\left(2^{-1} \\bar{v}_{j1}\\right)u_1 + \\left(2^{-2} \\bar{v}_{j2}\\right)u_2 + \\dots + \\left(2^{-80} \\bar{v}_{j,80}\\right)u_{80} $$ \n",
    "    \n",
    "    - Where $ \\left(2^{-1} \\bar{v}_{j1}\\right) $ is a scalar, and since $v$ is uniformly\n",
    "    random between 0 and 1, we know that $ \\bar{v}_{j1} \\approx 0.1$\n",
    "    \n",
    "    - So, the scalar in front of each $u_i$ is on the order of $\\left(0.1\\, 2^{-i}\\right)$.\n",
    "    \n",
    "    - Then during the orthogonalization for $QR$, the first column $q_1$ will be dominated by the *largest* component of $a_1$, namely $u_1$.  Thus, it will have norm on the order of $\\left( 0.1\\, 2^{-1} \\right)$.\n",
    "    \n",
    "    - The next step of orthogonalization (creating $v_2$) will orthogonalize $a_2$ against $q_1$ in order to obtain $v_2$.  This will leave $v_2$ dominated by the $u_2$ term, with $\\| v_2\\| \\sim \\left( 0.1\\, 2^{-2}\\right)$.  \n",
    "        - Remember, this $v_2$ goes on to form $q_2$\n",
    "    \n",
    "    - This argument repeats itself, and remembering that $r_{jj}$ equals the eventual norm of $v_j$, this explains the pattern of the diagonal entries of $R$.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagongal entries of $R$ should (roughly) decrease geometrically\n",
    "- But, for classical Gram-Schmidt, these values stagnate at about $10^{-7}=\\sqrt{\\epsilon_{mach}}$\n",
    "\n",
    "- Whereas for modified Gram-Schmidt, these values stagnate at about $10^{-15} = \\epsilon_{mach}$\n",
    "\n",
    "We see that modified Gram-Schmidt is able to orthogonalize up to the order of machine epsilon $\\left( \\epsilon_{mach} \\right)$, instead of square-root of machine epsilon.\n",
    "\n",
    "__Modified Gram-Schmit Gives Eight Orders More of Accuracy!!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on to another experiment.  This time focusing on numerical loss of orthogonality\n",
    "- Both modified and classical Gram-Schmidt may produce vectors $q_j$ that are far from orthogonal\n",
    "- Although, as we've seen, modified Gram-Schmidt usually loses less precision\n",
    "- This loss of orthogonality is pronounced with cond$(A)$ is *large*\n",
    "- We can even see this phenomenon for very small matrices\n",
    "- Consider the below $A$ and Gram-Schmidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7     0.70711]\n",
      " [0.70001 0.70711]]\n",
      "---\n",
      "280016.278127884\n"
     ]
    }
   ],
   "source": [
    "# Let's consider an ill-conditioned A, and observe loss of orthogonality\n",
    "A = np.array([[0.7, 0.70711], [0.70001, 0.70711]])\n",
    "from numpy.linalg import cond\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "print(A)\n",
    "print('---')\n",
    "print(cond(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider doing Gram-Schmidt on a machine with 5 decimal digits of precision (manually)\n",
    "   - Note, all results will be rounded to 5 digits\n",
    "\n",
    "Step $j = 1$\n",
    "1. $r_{11} = 0.98996 = \\| a_1\\|$\n",
    "     \n",
    "1. $q_1 = a_1/r_{11} = \n",
    "     \\begin{bmatrix} 0.70000/0.98996 \\\\ 0.70001/0.98996 \\end{bmatrix} =\n",
    "     \\begin{bmatrix} 0.70710 \\\\ 0.70711 \\end{bmatrix}$\n",
    "     \n",
    "Step $j=2$\n",
    "1. Here, Gram-Schmidt takes $a_2$ and projects out the component of $a_2$ in the direction of $q_1$\n",
    "1. $r_{12} = q^*_1 a_2 = 0.70710 \\cdot 0.70711 + 0.70711 \\cdot 0.70711 = 1.0000$\n",
    "    - Note that the inner product of $q_1$ and $a_2$ is essentially 1.0\n",
    "    - Taking that fact together with the fact that $q_1$ is norm 1, we can see that these two vectors are essentially the same (to within precision)\n",
    "1. $v_2 = a_2 - r_{12} q_1 = \\begin{bmatrix} 0.00001 \\\\ 0.00000 \\end{bmatrix}$\n",
    "    - This result is dominated by rounding errors.\n",
    "    - Our five digits of precision indicate that $a_1$ and $a_2$ are almost\n",
    "    linearly dependent\n",
    "    \n",
    "1. Final column of $Q$ is $q_2 = \\begin{bmatrix} 1.0000 \\\\ 0.00000 \\end{bmatrix}$\n",
    "\n",
    "What does our modified Gram-Schmidt say $Q$ should be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mod_GS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-24df75090661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod_GS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mod_GS' is not defined"
     ]
    }
   ],
   "source": [
    "[Q,R] = mod_GS(A)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa! That $Q$ is way different.  \n",
    "\n",
    "But did we still lose orthogonality in our 15-16 digit precision finite arithmetic?\n",
    "- Measure orthogonality loss with \n",
    "$$ \\| Q^* Q - I \\|_2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sla.norm(np.dot(Q.T,Q) - np.eye(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the library $QR$ which uses Householder (better than Gram-Schmidt for orthogonality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Q,R] = sla.qr(A)\n",
    "print(sla.norm(np.dot(Q.T,Q) - np.eye(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Thoughts__\n",
    "- What if $A$ is complex valued?\n",
    "    - What do we need to change above?\n",
    "    - Does the order of any dot products matter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
